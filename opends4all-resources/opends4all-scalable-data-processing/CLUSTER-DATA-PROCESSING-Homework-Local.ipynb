{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lecture_Notebook_Local.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cy6hpgnJY-Rp","colab_type":"text"},"source":["# Lecture Notebook: Big Data and Graph Data\n","\n","Apache Spark is a big data engine that runs on compute clusters, including on the cloud.  Since not everyone will have access to a compute cluster, this version of the notebook is set up to run Spark locally.\n"]},{"cell_type":"code","metadata":{"id":"oPw_ePbge5xR","colab_type":"code","outputId":"91e4d0c0-aef7-49a6-b723-7d12280b490a","executionInfo":{"status":"ok","timestamp":1576177399558,"user_tz":300,"elapsed":72700,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!apt install libkrb5-dev\n","!pip install sparkmagic\n","!pip install pyspark"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  comerr-dev krb5-multidev libgssrpc4 libkadm5clnt-mit11 libkadm5srv-mit11\n","  libkdb5-9\n","Suggested packages:\n","  doc-base krb5-doc krb5-user\n","The following NEW packages will be installed:\n","  comerr-dev krb5-multidev libgssrpc4 libkadm5clnt-mit11 libkadm5srv-mit11\n","  libkdb5-9 libkrb5-dev\n","0 upgraded, 7 newly installed, 0 to remove and 7 not upgraded.\n","Need to get 349 kB of archives.\n","After this operation, 1,992 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgssrpc4 amd64 1.16-2ubuntu0.1 [54.2 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkdb5-9 amd64 1.16-2ubuntu0.1 [37.2 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkadm5srv-mit11 amd64 1.16-2ubuntu0.1 [49.7 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkadm5clnt-mit11 amd64 1.16-2ubuntu0.1 [38.2 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 comerr-dev amd64 2.1-1.44.1-1ubuntu1.2 [38.5 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 krb5-multidev amd64 1.16-2ubuntu0.1 [120 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkrb5-dev amd64 1.16-2ubuntu0.1 [11.8 kB]\n","Fetched 349 kB in 1s (296 kB/s)\n","Selecting previously unselected package libgssrpc4:amd64.\n","(Reading database ... 134983 files and directories currently installed.)\n","Preparing to unpack .../0-libgssrpc4_1.16-2ubuntu0.1_amd64.deb ...\n","Unpacking libgssrpc4:amd64 (1.16-2ubuntu0.1) ...\n","Selecting previously unselected package libkdb5-9:amd64.\n","Preparing to unpack .../1-libkdb5-9_1.16-2ubuntu0.1_amd64.deb ...\n","Unpacking libkdb5-9:amd64 (1.16-2ubuntu0.1) ...\n","Selecting previously unselected package libkadm5srv-mit11:amd64.\n","Preparing to unpack .../2-libkadm5srv-mit11_1.16-2ubuntu0.1_amd64.deb ...\n","Unpacking libkadm5srv-mit11:amd64 (1.16-2ubuntu0.1) ...\n","Selecting previously unselected package libkadm5clnt-mit11:amd64.\n","Preparing to unpack .../3-libkadm5clnt-mit11_1.16-2ubuntu0.1_amd64.deb ...\n","Unpacking libkadm5clnt-mit11:amd64 (1.16-2ubuntu0.1) ...\n","Selecting previously unselected package comerr-dev:amd64.\n","Preparing to unpack .../4-comerr-dev_2.1-1.44.1-1ubuntu1.2_amd64.deb ...\n","Unpacking comerr-dev:amd64 (2.1-1.44.1-1ubuntu1.2) ...\n","Selecting previously unselected package krb5-multidev:amd64.\n","Preparing to unpack .../5-krb5-multidev_1.16-2ubuntu0.1_amd64.deb ...\n","Unpacking krb5-multidev:amd64 (1.16-2ubuntu0.1) ...\n","Selecting previously unselected package libkrb5-dev:amd64.\n","Preparing to unpack .../6-libkrb5-dev_1.16-2ubuntu0.1_amd64.deb ...\n","Unpacking libkrb5-dev:amd64 (1.16-2ubuntu0.1) ...\n","Setting up libgssrpc4:amd64 (1.16-2ubuntu0.1) ...\n","Setting up comerr-dev:amd64 (2.1-1.44.1-1ubuntu1.2) ...\n","Setting up libkdb5-9:amd64 (1.16-2ubuntu0.1) ...\n","Setting up libkadm5srv-mit11:amd64 (1.16-2ubuntu0.1) ...\n","Setting up libkadm5clnt-mit11:amd64 (1.16-2ubuntu0.1) ...\n","Setting up krb5-multidev:amd64 (1.16-2ubuntu0.1) ...\n","Setting up libkrb5-dev:amd64 (1.16-2ubuntu0.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","Collecting sparkmagic\n","  Downloading https://files.pythonhosted.org/packages/70/43/75737ebeec472e0b30c11904737ad1a0b9864ac2ed44a3b4495b297a39d5/sparkmagic-0.14.0.tar.gz\n","Collecting hdijupyterutils>=0.6\n","  Downloading https://files.pythonhosted.org/packages/c0/99/0a1a4a8c625beda3908613d69ba54d3367c9570773e86fae3ca2f338fbb2/hdijupyterutils-0.14.0.tar.gz\n","Collecting autovizwidget>=0.6\n","  Downloading https://files.pythonhosted.org/packages/7b/c8/71cbfc3f1a8029709de4744efe09d7fb5318b5a999bbb3a2efb4f5ed38e8/autovizwidget-0.14.0.tar.gz\n","Requirement already satisfied: ipython>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.5.0)\n","Collecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 14.1MB/s \n","\u001b[?25hCollecting mock\n","  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n","Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (0.25.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (1.17.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (2.21.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (4.6.1)\n","Requirement already satisfied: ipywidgets>5.0.0 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (7.5.1)\n","Requirement already satisfied: notebook>=4.2 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (5.2.2)\n","Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from sparkmagic) (4.5.3)\n","Collecting requests_kerberos>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/ee/a2/866f2b9a60f75055137b9ad127033e397963b2c4769d4b5fab1c3c7e8be3/requests_kerberos-0.12.0-py2.py3-none-any.whl\n","Requirement already satisfied: jupyter>=1 in /usr/local/lib/python3.6/dist-packages (from hdijupyterutils>=0.6->sparkmagic) (1.0.0)\n","Requirement already satisfied: plotly>=3 in /usr/local/lib/python3.6/dist-packages (from autovizwidget>=0.6->sparkmagic) (4.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.4.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (42.0.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.3.3)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (1.0.18)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (4.7.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (2.1.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.2->sparkmagic) (0.7.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from mock->sparkmagic) (1.12.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->sparkmagic) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->sparkmagic) (2.6.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->sparkmagic) (2.8)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->sparkmagic) (5.3.4)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>5.0.0->sparkmagic) (4.4.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>5.0.0->sparkmagic) (3.5.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (0.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (5.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (2.10.3)\n","Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (0.8.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.2->sparkmagic) (4.6.1)\n","Collecting pykerberos<2.0.0,>=1.1.8; sys_platform != \"win32\"\n","  Downloading https://files.pythonhosted.org/packages/9a/b8/1ec56b6fa8a2e2a81420bd3d90e70b59fc83f6b857fb2c2c37accddc8be3/pykerberos-1.2.1.tar.gz\n","Collecting cryptography>=1.3; python_version != \"3.3\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 49.0MB/s \n","\u001b[?25hRequirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (4.6.0)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter>=1->hdijupyterutils>=0.6->sparkmagic) (5.2.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=3->autovizwidget>=0.6->sparkmagic) (1.3.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.2->sparkmagic) (0.1.7)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.2->sparkmagic) (0.6.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->sparkmagic) (17.0.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>5.0.0->sparkmagic) (2.6.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.6.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (3.1.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (0.4.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.2->sparkmagic) (1.4.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.2->sparkmagic) (1.1.1)\n","Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.3; python_version != \"3.3\"->requests_kerberos>=0.8.0->sparkmagic) (1.13.2)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.2->sparkmagic) (0.5.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.3; python_version != \"3.3\"->requests_kerberos>=0.8.0->sparkmagic) (2.19)\n","Building wheels for collected packages: sparkmagic, hdijupyterutils, autovizwidget, pykerberos\n","  Building wheel for sparkmagic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sparkmagic: filename=sparkmagic-0.14.0-cp36-none-any.whl size=56739 sha256=305d802dad9a30f8d4f1be6c81d85bb0573932fe62250acfdffce0e17458a9e4\n","  Stored in directory: /root/.cache/pip/wheels/7c/d1/11/b08d355911a4eb136e52fd13b4807e748f03905a32ef01a3a4\n","  Building wheel for hdijupyterutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdijupyterutils: filename=hdijupyterutils-0.14.0-cp36-none-any.whl size=7666 sha256=e21a207d2d6d8526288a2f654ff47226064b26e538d61b358626c3f700feef9f\n","  Stored in directory: /root/.cache/pip/wheels/45/80/b5/1ff8f49225868c5c4d09ab50e05b06daa4b5b4666613a4d91f\n","  Building wheel for autovizwidget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autovizwidget: filename=autovizwidget-0.14.0-cp36-none-any.whl size=14549 sha256=049f5f6cc7b191c3dc0b6d78ffef18a1f2a49a1296350a93e1d8bdfba87ea74f\n","  Stored in directory: /root/.cache/pip/wheels/b8/99/65/f5a68dd355410f4174e11498081c48736287ac5b5bf5213927\n","  Building wheel for pykerberos (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pykerberos: filename=pykerberos-1.2.1-cp36-cp36m-linux_x86_64.whl size=68593 sha256=9d82997ea41334428a79d58d60593f1fdb6658f7fb2308922dbb343ee3379ef5\n","  Stored in directory: /root/.cache/pip/wheels/c7/a7/07/d414c22754acf5822ccce48b41822142974ec103057c8305e7\n","Successfully built sparkmagic hdijupyterutils autovizwidget pykerberos\n","Installing collected packages: nose, mock, hdijupyterutils, autovizwidget, pykerberos, cryptography, requests-kerberos, sparkmagic\n","Successfully installed autovizwidget-0.14.0 cryptography-2.8 hdijupyterutils-0.14.0 mock-3.0.5 nose-1.3.7 pykerberos-1.2.1 requests-kerberos-0.12.0 sparkmagic-0.14.0\n","Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n","\u001b[K     |████████████████████████████████| 215.7MB 59kB/s \n","\u001b[?25hCollecting py4j==0.10.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n","\u001b[K     |████████████████████████████████| 204kB 51.9MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=25a210a16661921488a5ccce4507269ba8d0f5d0f0dede0d08940072be19138e\n","  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.7 pyspark-2.4.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XrFAyi5re65W","colab_type":"code","colab":{}},"source":["%load_ext sparkmagic.magics"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qr8AfhqNG1_I","colab_type":"code","colab":{}},"source":["    import os\n","    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","    import pyspark\n","    from pyspark.sql import SparkSession\n","    from pyspark.sql.types import *\n","    import pyspark.sql.functions as F\n","    from pyspark.sql import SQLContext"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmtMSb0gHh7-","colab_type":"code","colab":{}},"source":["    try:\n","       if(spark == None):\n","            spark = SparkSession.builder.appName('Graphs').getOrCreate()\n","            sqlContext=SQLContext(spark)\n","    except NameError:\n","        spark = SparkSession.builder.appName('Graphs').getOrCreate()\n","        sqlContext=SQLContext(spark)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6u6rwG-wQIX2","colab_type":"text"},"source":["## Example of Loading Sharded Data"]},{"cell_type":"markdown","metadata":{"id":"8O02TOXqQLgt","colab_type":"text"},"source":["First let's load the data."]},{"cell_type":"code","metadata":{"id":"qDHoasDnQVLA","colab_type":"code","colab":{}},"source":["import json\n","import requests"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmXoH1gmtD2d","colab_type":"code","outputId":"94ebf87d-a626-48a4-b4c9-c163b7fa49cd","executionInfo":{"status":"ok","timestamp":1576177454118,"user_tz":300,"elapsed":127214,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Get 10K records from linkedin.\n","#linked_in = requests.get('X')\n","linked_in = requests.get('https://www.cis.upenn.edu/~cis545/xaa')\n","\n","my_list = [json.loads(line) for line in linked_in.iter_lines()]\n","len(my_list)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10000"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"El-Or-F-Qc5C","colab_type":"text"},"source":["## Load the list into Spark\n","\n","Spark needs to know the structure of the data in its dataframes, i.e., their schemas.  Since our JSON structure for LinkedIn is complex, we need to define the schema.\n","\n","There are some basic types:\n","  * The table is a `StructType` with a list of fields (each row)\n","  * Most fields, in our case, are `StringType`.\n","  * We also have nested dictionary for the name, which is a `MapType` from `StringType` keys to `StringType` values.\n","  * `skills` is an `ArrayType` since it's a list, and it contains `StringType`s.\n","  * `also_view` is an array of structs.\n","\n","See Pyspark documentation on `StructType` and examples such as https://www.programcreek.com/python/example/104715/pyspark.sql.types.StructType."]},{"cell_type":"code","metadata":{"id":"DN3NJaRuP8Tl","colab_type":"code","colab":{}},"source":["# Spark requires that we define a schema for the LinkedIn data...\n","from pyspark.sql.types import StringType, StructField, StructType, ArrayType, MapType\n","schema = StructType([\n","        StructField(\"_id\", StringType(), True),\n","        StructField(\"name\", MapType(StringType(), StringType()), True),\n","        StructField(\"locality\", StringType(), True),\n","        StructField(\"skills\", ArrayType(StringType()), True),\n","        StructField(\"industry\", StringType(), True),\n","        StructField(\"summary\", StringType(), True),\n","        StructField(\"url\", StringType(), True),\n","        StructField(\"also_view\", ArrayType(\\\n","                    StructType([\\\n","                      StructField(\"url\", StringType(), True),\\\n","                      StructField(\"id\", StringType(), True)])\\\n","                    ), True)\\\n","         ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmF8gC6nP3VW","colab_type":"code","outputId":"3edc489b-f19f-4b93-e59a-ad6bb1ce2613","executionInfo":{"status":"ok","timestamp":1576177461318,"user_tz":300,"elapsed":134393,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":222}},"source":["# Load the remote data as a list of dictionaries\n","linked_df = sqlContext.createDataFrame(my_list, schema).\\\n","      repartition('_id')\n","\n","linked_df.show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|            _id|                name|            locality|              skills|            industry|             summary|                 url|           also_view|\n","+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|     in-2432006|[given_name -> La...|   Genoa Area, Italy|[HR Consulting, E...|       Risorse umane|Ottobre 2012 - Ce...|http://it.linkedi...|[[http://it.linke...|\n","|      in-261076|[given_name -> Re...|London, United Ki...|[Information Secu...|  Financial Services|                null|http://uk.linkedi...|[[http://ch.linke...|\n","|in-4mikesandahl|[given_name -> Mi...| Greater Boston Area|[Lean Manufacturi...|              Design|                null|http://www.linked...|[[http://www.link...|\n","|       in-55432|[given_name -> Ma...|Salamanca y alred...|                null|Administración gu...|                null|http://es.linkedi...|[[http://es.linke...|\n","|      in-aaeran|[given_name -> An...|      United Kingdom|[CISSP, CISM, CIS...|Information Techn...|Strong consulting...|http://uk.linkedi...|[[http://uk.linke...|\n","+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r8TnR04oJVoJ","colab_type":"code","outputId":"7637394d-681c-4d9e-cb52-6f65ca545b0a","executionInfo":{"status":"ok","timestamp":1576177461320,"user_tz":300,"elapsed":134385,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["linked_df.rdd.getNumPartitions()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"DoUo_4LfOiki","colab_type":"code","outputId":"47800a31-9e00-46f8-a29a-85648e072ebc","executionInfo":{"status":"ok","timestamp":1576177463982,"user_tz":300,"elapsed":137038,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["linked_df.filter(linked_df.locality == 'United States')[['_id', 'name', 'locality']].show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----------------+--------------------+-------------+\n","|             _id|                name|     locality|\n","+----------------+--------------------+-------------+\n","|   in-aaronhrose|[given_name -> Aa...|United States|\n","|    in-akalderon|[given_name -> Av...|United States|\n","|      in-1solone|[given_name -> Ha...|United States|\n","|in-actiongarment|[given_name -> Da...|United States|\n","|   in-abhinethra|[given_name -> Ab...|United States|\n","+----------------+--------------------+-------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oj1E3-AJ1G_y","colab_type":"code","outputId":"014d1bd1-4f9f-4d1e-9cbd-3cc02431d9e2","executionInfo":{"status":"ok","timestamp":1576177464819,"user_tz":300,"elapsed":137866,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["linked_df.select(\"_id\", \"locality\").show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---------------+--------------------+\n","|            _id|            locality|\n","+---------------+--------------------+\n","|     in-2432006|   Genoa Area, Italy|\n","|      in-261076|London, United Ki...|\n","|in-4mikesandahl| Greater Boston Area|\n","|       in-55432|Salamanca y alred...|\n","|      in-aaeran|      United Kingdom|\n","+---------------+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e68gcPiaL5Wb","colab_type":"code","colab":{}},"source":["### Clean out the list from memory\n","my_list = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eD9SE_v-1v0C","colab_type":"code","outputId":"a8ffcab5-d4b3-43e1-bcad-ed110705e0b2","executionInfo":{"status":"ok","timestamp":1576177466990,"user_tz":300,"elapsed":140020,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":222}},"source":["linked_df.createOrReplaceTempView('linked_in')\n","sqlContext.sql('select * from linked_in').show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|            _id|                name|            locality|              skills|            industry|             summary|                 url|           also_view|\n","+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|     in-2432006|[given_name -> La...|   Genoa Area, Italy|[HR Consulting, E...|       Risorse umane|Ottobre 2012 - Ce...|http://it.linkedi...|[[http://it.linke...|\n","|      in-261076|[given_name -> Re...|London, United Ki...|[Information Secu...|  Financial Services|                null|http://uk.linkedi...|[[http://ch.linke...|\n","|in-4mikesandahl|[given_name -> Mi...| Greater Boston Area|[Lean Manufacturi...|              Design|                null|http://www.linked...|[[http://www.link...|\n","|       in-55432|[given_name -> Ma...|Salamanca y alred...|                null|Administración gu...|                null|http://es.linkedi...|[[http://es.linke...|\n","|      in-aaeran|[given_name -> An...|      United Kingdom|[CISSP, CISM, CIS...|Information Techn...|Strong consulting...|http://uk.linkedi...|[[http://uk.linke...|\n","+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yur38PPmVGt-","colab_type":"code","outputId":"8cadcf4b-2547-4e5f-8c53-0d6f6ff8f547","executionInfo":{"status":"ok","timestamp":1576177467900,"user_tz":300,"elapsed":140919,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["sqlContext.sql('select _id, name.given_name, name.first_name from linked_in').show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---------------+----------+----------+\n","|            _id|given_name|first_name|\n","+---------------+----------+----------+\n","|     in-2432006|     Laura|      null|\n","|      in-261076|     Renan|      null|\n","|in-4mikesandahl|      Mike|      null|\n","|       in-55432|     Marta|      null|\n","|      in-aaeran|     Ankur|      null|\n","+---------------+----------+----------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VcvsuNw9Tr6k","colab_type":"code","outputId":"f1cbee76-307d-4250-8f4a-05f2867deb02","executionInfo":{"status":"ok","timestamp":1576177469209,"user_tz":300,"elapsed":142218,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["from pyspark.sql.functions import udf\n","from pyspark.sql.types import StringType\n","\n","acro = udf(lambda x: ''.join([n[0] for n in x.split()]), StringType())\n","\n","linked_df.select(\"_id\", acro(\"locality\").alias(\"acronym\")).show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---------------+-------+\n","|            _id|acronym|\n","+---------------+-------+\n","|     in-2432006|    GAI|\n","|      in-261076|    LUK|\n","|in-4mikesandahl|    GBA|\n","|       in-55432|   SyaE|\n","|      in-aaeran|     UK|\n","+---------------+-------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bgMW4qFCQf4W","colab_type":"code","outputId":"928d9cb3-2d66-44ed-bf3a-c910e7e39c6b","executionInfo":{"status":"ok","timestamp":1576177476775,"user_tz":300,"elapsed":149775,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["# Which industries are most popular?\n","sqlContext.sql('select count(_id), industry '+\\\n","               'from linked_in '+\\\n","               'group by industry '+\\\n","               'order by count(_id) desc').\\\n","    show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----------+--------------------+\n","|count(_id)|            industry|\n","+----------+--------------------+\n","|      1198|Information Techn...|\n","|       781|   Computer Software|\n","|       482|Marketing and Adv...|\n","|       397|            Internet|\n","|       323|  Financial Services|\n","+----------+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WRrsSWsmI7pG","colab_type":"text"},"source":["## Graphs\n","\n","For the next set of examples, we will look at graph-structured data.  It turns out our LinkedIn dataset has a list of nodes (by int ID, but associated with the user ID we used in the linked_in table) and a list of edges."]},{"cell_type":"code","metadata":{"id":"aLkmsCn02FKQ","colab_type":"code","colab":{}},"source":["import urllib\n","import zipfile\n","import os\n","\n","url = 'https://upenn-bigdataanalytics.s3.amazonaws.com/linkedin.edges.zip'\n","filehandle, _ = urllib.request.urlretrieve(url)\n","\n","zip_file_object = zipfile.ZipFile(filehandle, 'r')\n","fname = zip_file_object.open('linkedin.edges')\n","\n","edges = []\n","MAX = 100000\n","\n","for link in fname:\n","  edge = link.decode('utf-8').split(' ')\n","  edges.append([int(edge[0]), int(edge[1])])\n","  if len(edges) >= MAX:\n","    break\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"10raoCWVJQXk","colab_type":"code","outputId":"bb9b4dcc-f02d-4209-bf02-21e5bd033155","executionInfo":{"status":"ok","timestamp":1576177480860,"user_tz":300,"elapsed":153844,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["from pyspark.sql.types import IntegerType\n","schema = StructType([\n","        StructField(\"from\", IntegerType(), True),\n","        StructField(\"to\", IntegerType(), True)\n","         ])\n","# Load the remote data as a list of dictionaries\n","edges_df = sqlContext.createDataFrame(edges, schema)\n","\n","edges_df.show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----+-------+\n","|from|     to|\n","+----+-------+\n","|   0|2152448|\n","|   0|1656491|\n","|   0| 399364|\n","|   0|  18448|\n","|   0|  72025|\n","+----+-------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sV4WTTHohshi","colab_type":"code","outputId":"2b9299fb-801d-489a-b6ad-26ad55678030","executionInfo":{"status":"ok","timestamp":1576177481602,"user_tz":300,"elapsed":154574,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["edges_df.createOrReplaceTempView('edges')\n","sqlContext.sql('select from as id, count(to) as degree from edges group by from').show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---+------+\n","| id|degree|\n","+---+------+\n","|148|   140|\n","|463|    93|\n","|471|    88|\n","|496|    88|\n","|833|    76|\n","+---+------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kbXkhbzOk1ZK","colab_type":"text"},"source":["## Traversing the Graph"]},{"cell_type":"code","metadata":{"id":"PAJ_BjL1kiQi","colab_type":"code","outputId":"0c1523c2-657e-4b4e-fd9f-7b4e5c6b9030","executionInfo":{"status":"ok","timestamp":1576177483435,"user_tz":300,"elapsed":156396,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["from pyspark.sql.functions import col\n","\n","# Start with a subset of nodes\n","start_nodes_df = edges_df[['from']].filter(edges_df['from'] < 1000).\\\n","  select(col('from').alias('id')).drop_duplicates()\n","\n","start_nodes_df.show(5)\n","\n","# The neighbors require us to join\n","# and we'll use Spark DataFrames syntax here\n","neighbor_nodes_df = start_nodes_df.\\\n","  join(edges_df, start_nodes_df.id == edges_df['from']).\\\n","  select(col('to').alias('id'))\n","\n","neighbor_nodes_df.show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---+\n","| id|\n","+---+\n","|148|\n","|463|\n","|471|\n","|496|\n","|833|\n","+---+\n","only showing top 5 rows\n","\n","+-------+\n","|     id|\n","+-------+\n","|1510404|\n","|    523|\n","| 993804|\n","| 469009|\n","| 232979|\n","+-------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LpoPxuPQnmNQ","colab_type":"code","outputId":"86301c1c-cf5c-4829-af63-d87d63f33ad3","executionInfo":{"status":"ok","timestamp":1576177484936,"user_tz":300,"elapsed":157887,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":890}},"source":["edges_df[['from']].orderBy('from').drop_duplicates().show()\n","\n","edges_df.filter(edges_df['from'] == 1).show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----+\n","|from|\n","+----+\n","|   0|\n","|   1|\n","|   2|\n","|   3|\n","|   4|\n","|   5|\n","|   6|\n","|   7|\n","|   8|\n","|   9|\n","|  10|\n","|  11|\n","|  12|\n","|  13|\n","|  14|\n","|  15|\n","|  16|\n","|  17|\n","|  18|\n","|  19|\n","+----+\n","only showing top 20 rows\n","\n","+----+-------+\n","|from|     to|\n","+----+-------+\n","|   1|  77832|\n","|   1| 542731|\n","|   1| 317452|\n","|   1|  27650|\n","|   1|2662416|\n","|   1| 104468|\n","|   1| 176149|\n","|   1|     25|\n","|   1|  53282|\n","|   1| 516132|\n","|   1|  47142|\n","|   1| 104488|\n","|   1| 262186|\n","|   1|1392685|\n","|   1| 523471|\n","|   1| 110639|\n","|   1| 700465|\n","|   1|1941562|\n","|   1| 116809|\n","|   1|1837130|\n","+----+-------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N-pnH4lKqNiV","colab_type":"code","outputId":"ceb4316b-53f5-4f18-fb5e-bac45c755d7c","executionInfo":{"status":"ok","timestamp":1576177493171,"user_tz":300,"elapsed":166110,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["neighbor_neighbor_nodes_df = neighbor_nodes_df.\\\n","  join(edges_df, neighbor_nodes_df.id == edges_df['from']).\\\n","  select(col('to').alias('id'))\n","\n","neighbor_neighbor_nodes_df.show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+-------+\n","|     id|\n","+-------+\n","| 445099|\n","| 435723|\n","|1666062|\n","| 390673|\n","|2328084|\n","+-------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZvsJ2_LNsTbe","colab_type":"code","colab":{}},"source":["def iterate(df, depth):\n","  df.createOrReplaceTempView('iter')\n","\n","  # Base case: direct connection\n","  result = sqlContext.sql('select from, to, 1 as depth from iter')\n","\n","  for i in range(1, depth):\n","    result.createOrReplaceTempView('result')\n","    result = sqlContext.sql('select r1.from as from, r2.to as to, r1.depth+1 as depth  '\\\n","                            'from result r1 join iter r2 '\\\n","                            'on r1.to=r2.from')\n","  return result"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjiE4BBMuwqv","colab_type":"code","outputId":"b750ad80-cabe-4464-e5a0-48fd2454a0ce","executionInfo":{"status":"ok","timestamp":1576177493689,"user_tz":300,"elapsed":166610,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":454}},"source":["iterate(edges_df.filter(edges_df['from'] < 1000), 1).orderBy('from','to').show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----+----+-----+\n","|from|  to|depth|\n","+----+----+-----+\n","|   0|  38|    1|\n","|   0| 101|    1|\n","|   0| 121|    1|\n","|   0| 161|    1|\n","|   0| 337|    1|\n","|   0| 487|    1|\n","|   0| 504|    1|\n","|   0| 802|    1|\n","|   0|1379|    1|\n","|   0|1583|    1|\n","|   0|1961|    1|\n","|   0|1982|    1|\n","|   0|1996|    1|\n","|   0|2250|    1|\n","|   0|2409|    1|\n","|   0|2692|    1|\n","|   0|3179|    1|\n","|   0|3250|    1|\n","|   0|3787|    1|\n","|   0|4213|    1|\n","+----+----+-----+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"63RGiC1euw-y","colab_type":"code","outputId":"0b7ab238-5d45-4fa4-b65a-eb00bbec673e","executionInfo":{"status":"ok","timestamp":1576177495822,"user_tz":300,"elapsed":168732,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":454}},"source":["iterate(edges_df.filter(edges_df['from'] < 1000), 2).orderBy('from','to').show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----+---+-----+\n","|from| to|depth|\n","+----+---+-----+\n","|   0| 59|    2|\n","|   0| 66|    2|\n","|   0|101|    2|\n","|   0|121|    2|\n","|   0|121|    2|\n","|   0|161|    2|\n","|   0|236|    2|\n","|   0|236|    2|\n","|   0|236|    2|\n","|   0|337|    2|\n","|   0|337|    2|\n","|   0|337|    2|\n","|   0|487|    2|\n","|   0|487|    2|\n","|   0|487|    2|\n","|   0|487|    2|\n","|   0|504|    2|\n","|   0|504|    2|\n","|   0|504|    2|\n","|   0|504|    2|\n","+----+---+-----+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2wG7vMrXuxFr","colab_type":"code","outputId":"269b7582-3bff-4429-950e-5f071d650e26","executionInfo":{"status":"ok","timestamp":1576177499987,"user_tz":300,"elapsed":172884,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":454}},"source":["iterate(edges_df.filter(edges_df['from'] < 1000), 3).orderBy('from','to').show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+----+---+-----+\n","|from| to|depth|\n","+----+---+-----+\n","|   0|101|    3|\n","|   0|101|    3|\n","|   0|121|    3|\n","|   0|121|    3|\n","|   0|121|    3|\n","|   0|236|    3|\n","|   0|236|    3|\n","|   0|236|    3|\n","|   0|337|    3|\n","|   0|337|    3|\n","|   0|337|    3|\n","|   0|337|    3|\n","|   0|337|    3|\n","|   0|337|    3|\n","|   0|337|    3|\n","|   0|337|    3|\n","|   0|487|    3|\n","|   0|487|    3|\n","|   0|487|    3|\n","|   0|487|    3|\n","+----+---+-----+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8N1eHyunMccX","colab_type":"code","colab":{}},"source":["# Clear list of edges from Python memory\n","# to free up space\n","edges = []\n","\n","\n","### Now let's get the list of node IDs\n","url = 'https://upenn-bigdataanalytics.s3.amazonaws.com/linkedin.nodes.zip'\n","nodehandle, _ = urllib.request.urlretrieve(url)\n","\n","zip_file_object = zipfile.ZipFile(nodehandle, 'r')\n","fname = zip_file_object.open('linkedin.nodes')\n","\n","nodes = []\n","MAX = 100000\n","\n","for node in fname:\n","  node_tuple = node.decode('utf-8').split()\n","  nodes.append([int(node_tuple[0]), str(node_tuple[1])])\n","  if len(nodes) >= MAX:\n","    break\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"akCba0mxkikw","colab_type":"text"},"source":["## Joins in Spark, Beyond Graph Traversals\n","\n","What if we want to connect our edges to the people from our previous crawl?  Sadly the edges use int node IDs that don't correspond to the people dataframe.  But in fact the node data includes this information, so let's load and exploit that."]},{"cell_type":"markdown","metadata":{"id":"4wg-2C56pP_s","colab_type":"text"},"source":["Let's load the information about nodes, and their correspondence to the user ID."]},{"cell_type":"code","metadata":{"id":"f3iZL-pWX8xd","colab_type":"code","outputId":"4212f34e-8113-4d12-a72f-3ed37855154c","executionInfo":{"status":"ok","timestamp":1576177503720,"user_tz":300,"elapsed":176598,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["schema = StructType([\n","        StructField(\"nid\", IntegerType(), True),\n","        StructField(\"user\", StringType(), True)\n","         ])\n","# Load the remote data as a list of dictionaries\n","nodes_df = sqlContext.createDataFrame(nodes, schema)\n","\n","nodes_df.show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","|nid|                user|\n","+---+--------------------+\n","|  0|pub-sandra-arana-...|\n","|  1|     in-sehrishhafiz|\n","|  2|pub-heba-bayoumi-...|\n","|  3|pub-aysha-binbrai...|\n","|  4|      in-rubabadowla|\n","+---+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ecVwMCIspVPc","colab_type":"text"},"source":["## Finding Friends, by ID"]},{"cell_type":"code","metadata":{"id":"18K1_i1jZ94B","colab_type":"code","outputId":"c7d548c0-9c42-42a1-9578-5e987f6e9228","executionInfo":{"status":"ok","timestamp":1576177511140,"user_tz":300,"elapsed":184009,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["nodes_df.createOrReplaceTempView('nodes')\n","edges_df.createOrReplaceTempView('edges')\n","\n","friends_df = \\\n","sqlContext.sql('select n1.user, n2.user as friend ' +\\\n","               'from (nodes n1 join edges e on n1.nid = e.from) join nodes n2 on e.to = n2.nid')\n","\n","friends_df.show(5)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+--------------------+--------------------+\n","|                user|              friend|\n","+--------------------+--------------------+\n","|pub-sara-muÃ±oz-r...|pub-rebeca-arroyo...|\n","|pub-gloria-villal...|pub-rebeca-arroyo...|\n","|in-dianacolliabugeda|pub-rebeca-arroyo...|\n","|        in-maitepena|pub-rebeca-arroyo...|\n","|         in-alvarovl|pub-begoÃ±a-landa...|\n","+--------------------+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Lp5VkLumpYmT","colab_type":"text"},"source":["## Connecting Friends to Names"]},{"cell_type":"code","metadata":{"id":"b_9PkrJobXY0","colab_type":"code","outputId":"a7efe8d0-3071-4ed0-af75-55e042bc9791","executionInfo":{"status":"ok","timestamp":1576177528155,"user_tz":300,"elapsed":201015,"user":{"displayName":"Leshang Chen","photoUrl":"","userId":"00573172153387237137"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["friends_df.createOrReplaceTempView('friends')\n","\n","sqlContext.sql('select u1.name.given_name as user, u2.name.given_name as friend '+\\\n","               'from (linked_in u1 join friends on u1._id = user) join linked_in u2 on u2._id = friend').show(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["+------------+------+\n","|        user|friend|\n","+------------+------+\n","|Maria Isabel|  Alba|\n","+------------+------+\n","\n"],"name":"stdout"}]}]}